{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv('Dataset/train.csv', index_col='pet_id')\n",
    "test_data = pd.read_csv('Dataset/test.csv', index_col='pet_id')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_data['color_type_encoded'] = encoder.fit_transform(train_data.color_type)\n",
    "test_data['color_type_encoded'] = encoder.transform(test_data.color_type)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_condition=np.random.choice(np.arange(0, 3), p=[6281/17357,6819/17357,4257/17357], size=1477)\n",
    "\n",
    "\n",
    "\n",
    "test_condition = np.random.choice(np.arange(0,3), p=[2685/7453,2928/7453,1840/7453], size=619)\n",
    "\n",
    "train_data['condition_filled'] = 0\n",
    "test_data['condition_filled'] = 0\n",
    "\n",
    "train_data.loc[train_data.condition.isnull(), 'condition_filled'] = 1\n",
    "test_data.loc[test_data.condition.isnull(), 'condition_filled'] = 1\n",
    "\n",
    "train_data.loc[train_data.condition.isnull(), 'condition'] = train_condition\n",
    "test_data.loc[test_data.condition.isnull(), 'condition'] = test_condition\n",
    "\n",
    "train_data['issue_date'] = pd.to_datetime(train_data.issue_date)\n",
    "train_data['listing_date'] = pd.to_datetime(train_data.listing_date)\n",
    "                                            \n",
    "test_data['issue_date'] = pd.to_datetime(test_data.issue_date)\n",
    "test_data['listing_date'] = pd.to_datetime(test_data.listing_date)\n",
    "\n",
    "train_data['issue_year'] = train_data.issue_date.dt.year\n",
    "train_data['issue_month'] = train_data.issue_date.dt.month\n",
    "train_data['issue_day'] = train_data.issue_date.dt.day\n",
    "\n",
    "train_data['listing_year'] = train_data.listing_date.dt.year\n",
    "train_data['listing_month'] = train_data.listing_date.dt.month\n",
    "train_data['listing_day'] = train_data.listing_date.dt.day\n",
    "\n",
    "test_data['issue_year'] = test_data.issue_date.dt.year\n",
    "test_data['issue_month'] = test_data.issue_date.dt.month\n",
    "test_data['issue_day'] = test_data.issue_date.dt.day\n",
    "\n",
    "test_data['listing_year'] = test_data.listing_date.dt.year\n",
    "test_data['listing_month'] = test_data.listing_date.dt.month\n",
    "test_data['listing_day'] = test_data.listing_date.dt.day\n",
    "\n",
    "train_data['total_days'] = np.array(train_data.listing_date-train_data.issue_date).astype('timedelta64[D]').astype('int64')\n",
    "test_data['total_days'] = np.array(test_data.listing_date-test_data.issue_date).astype('timedelta64[D]').astype('int64')\n",
    "\n",
    "train_data['length(cm)'] = train_data['length(m)']*100\n",
    "test_data['length(cm)'] = test_data['length(m)']*100\n",
    "\n",
    "train_data['rec_area'] = train_data['length(cm)'] * train_data['height(cm)']\n",
    "test_data['rec_area'] = test_data['length(cm)'] * test_data['height(cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['condition', 'length(cm)', 'height(cm)','rec_area', 'X1', 'X2', 'color_type_encoded',\n",
    "           'issue_year', 'issue_month', 'issue_day', 'listing_year', 'listing_month', 'listing_day', 'total_days']\n",
    "X = np.array(train_data[features])\n",
    "y_pet = np.array(train_data['pet_category'])\n",
    "y_breed = np.array(train_data['breed_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(X, y_pet, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pet_gbt = GradientBoostingClassifier(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=13, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_gbt.fit(X_pet_train, y_pet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8800106185293337"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_gbt.score(X_pet_valid, y_pet_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=13, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_gbt.fit(X, y_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features]), y_breed, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=13, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_gbt = GradientBoostingClassifier(random_state=13)\n",
    "breed_gbt.fit(X_breed_train, y_breed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8778869126625962"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_gbt.score(X_breed_valid, y_breed_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=13, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_gbt.fit(X, y_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_gbt_pred = pet_gbt.predict(X_test)\n",
    "breed_gbt_pred = breed_gbt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_gbt_preds = pd.DataFrame({'pet_id':test_data.index, 'breed_category':breed_gbt_pred, 'pet_category':pet_gbt_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_gbt_preds = gbt_gbt_preds.set_index('pet_id', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_gbt_preds.to_csv(\"gbt_gbt_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_features = features+['pet_category']\n",
    "pet_features = features+['breed_category']\n",
    "breed_from_pet_gbt = GradientBoostingClassifier(random_state=13)\n",
    "\n",
    "pet_from_breed = GradientBoostingClassifier(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scores = []\n",
    "def fit_models():\n",
    "    features = ['condition', 'length(cm)', 'height(cm)','rec_area', 'X1', 'X2', 'color_type_encoded',\n",
    "                'issue_year', 'issue_month', 'issue_day', 'listing_year', 'listing_month', 'listing_day', 'total_days']\n",
    "    y_pet = np.array(train_data['pet_category'])\n",
    "    y_breed = np.array(train_data['breed_category'])\n",
    "    \n",
    "    X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(np.array(train_data[features]), y_pet, test_size=0.20)\n",
    "    pet_gbt = GradientBoostingClassifier(random_state=13)\n",
    "    pet_gbt.fit(X_pet_train, y_pet_train)\n",
    "    scores.append(pet_gbt.score(X_pet_valid, y_pet_valid))\n",
    "    pet_gbt.fit(np.array(train_data[features]), y_pet)\n",
    "    \n",
    "    X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features+['pet_category']]), y_breed, test_size=0.20)\n",
    "    breed_gbt = GradientBoostingClassifier(random_state=13)\n",
    "    breed_gbt.fit(X_breed_train, y_breed_train)\n",
    "    scores.append(breed_gbt.score(X_breed_valid, y_breed_valid))\n",
    "    breed_gbt.fit(train_data[features+['pet_category']], y_breed)\n",
    "    \n",
    "    X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(np.array(train_data[features+['breed_category']]), y_pet, test_size=0.20)\n",
    "    pet_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "    pet_gbt_2.fit(X_pet_train, y_pet_train)\n",
    "    scores.append(pet_gbt_2.score(X_pet_valid, y_pet_valid))\n",
    "    pet_gbt_2.fit(train_data[features+['breed_category']], y_pet)\n",
    "    \n",
    "    X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features+['pet_category']]), y_breed, test_size=0.20)\n",
    "    breed_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "    breed_gbt_2.fit(X_breed_train, y_breed_train)\n",
    "    scores.append(breed_gbt_2.score(X_breed_valid, y_breed_valid))\n",
    "    breed_gbt.fit(train_data[features+['pet_category']], y_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "features = ['condition', 'length(cm)', 'height(cm)','rec_area', 'X1', 'X2', 'color_type_encoded',\n",
    "            'issue_year', 'issue_month', 'issue_day', 'listing_year', 'listing_month', 'listing_day', 'total_days']\n",
    "y_pet = np.array(train_data['pet_category'])\n",
    "y_breed = np.array(train_data['breed_category'])\n",
    "class models:\n",
    "    def __init__(self):\n",
    "        self.pet_gbt = GradientBoostingClassifier(random_state=13)\n",
    "        self.breed_gbt = GradientBoostingClassifier(random_state=13)\n",
    "        self.pet_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "        self.breed_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "        \n",
    "    def evaluate_combination(self):\n",
    "        scores = []\n",
    "        \n",
    "        X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(np.array(train_data[features]), \n",
    "                                                                              y_pet, test_size=0.20)\n",
    "        #self.pet_gbt = GradientBoostingClassifier(random_state=13)\n",
    "        self.pet_gbt.fit(X_pet_train, y_pet_train)\n",
    "        scores.append(self.pet_gbt.score(X_pet_valid, y_pet_valid))\n",
    "        \n",
    "        \n",
    "        X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features+['pet_category']]), \n",
    "                                                                                      y_breed, test_size=0.20)\n",
    "        #self.breed_gbt = GradientBoostingClassifier(random_state=13)\n",
    "        self.breed_gbt.fit(X_breed_train, y_breed_train)\n",
    "        scores.append(self.breed_gbt.score(X_breed_valid, y_breed_valid))\n",
    "        \n",
    "        \n",
    "        X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(np.array(train_data[features+['breed_category']]),\n",
    "                                                                              y_pet, test_size=0.20)\n",
    "        #self.pet_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "        self.pet_gbt_2.fit(X_pet_train, y_pet_train)\n",
    "        scores.append(self.pet_gbt_2.score(X_pet_valid, y_pet_valid))\n",
    "        \n",
    "        \n",
    "        X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features+['pet_category']]),\n",
    "                                                                                      y_breed, test_size=0.20)\n",
    "        #self.breed_gbt_2 = GradientBoostingClassifier(random_state=13)\n",
    "        self.breed_gbt_2.fit(X_breed_train, y_breed_train)\n",
    "        scores.append(self.breed_gbt_2.score(X_breed_valid, y_breed_valid))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features]),\n",
    "                                                                                      y_breed, test_size=0.20)\n",
    "        self.breeds_gbt.fit(X_breed_train, y_breed_train)\n",
    "        scores.append(self.breeds_gbt.score(X_breed_valid, y_breed_valid))\n",
    "        \n",
    "        X_pet_train, X_pet_valid, y_pet_train, y_pet_valid = train_test_split(np.array(train_data[features+['breed_category']]),\n",
    "                                                                              y_pet, test_size=0.20)\n",
    "        self.pets_gbt.fit(X_pet_train, y_pet_train)\n",
    "        scores.append(self.pets_gbt.score(X_pet_valid, y_pet_valid))\n",
    "        \n",
    "        X_breed_train, X_breed_valid, y_breed_train, y_breed_valid = train_test_split(np.array(train_data[features+['pet_category']]), \n",
    "                                                                                      y_breed, test_size=0.20)\n",
    "        self.breeds_gbt_2.fit(X_breed_train, y_breed_train)\n",
    "        scores.append(self.breeds_gbt_2.score(X_breed_valid, y_breed_valid))'''\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def fit_model(self):\n",
    "        self.pet_gbt.fit(np.array(train_data[features]), y_pet)\n",
    "        self.breed_gbt.fit(np.array(train_data[features+['pet_category']]), y_breed)\n",
    "        self.pet_gbt_2.fit(np.array(train_data[features+['breed_category']]), y_pet)\n",
    "        self.breed_gbt_2.fit(np.array(train_data[features+['pet_category']]), y_breed)\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        for i in range(5):\n",
    "            pet_category = self.pet_gbt.predict(np.array(test_data[features]))\n",
    "            test_data['pet_category'] = pet_category\n",
    "            self.pet_gbt.fit(test_data[features], pet_category)\n",
    "\n",
    "            breed_category = self.breed_gbt.predict(np.array(test_data[features+['pet_category']]))\n",
    "            test_data['breed_category'] = breed_category\n",
    "            self.breed_gbt.fit(test_data[features+['pet_category']], breed_category)\n",
    "\n",
    "\n",
    "            pet_category = self.pet_gbt_2.predict(np.array(test_data[features+['breed_category']]))\n",
    "            test_data['pet_category'] = pet_category\n",
    "            self.pet_gbt_2.fit(test_data[features+['breed_category']], pet_category)\n",
    "\n",
    "            breed_category = self.breed_gbt_2.predict(np.array(test_data[features+['pet_category']]))\n",
    "            test_data['breed_category'] = breed_category\n",
    "            self.breed_gbt_2.fit(test_data[features+['pet_category']], breed_category)\n",
    "            \n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "\n",
    "        \n",
    "    def prepare_submission(self, n):\n",
    "        breeds = test_data.breed_category.values\n",
    "        pets = test_data.pet_category.values\n",
    "        submission_dataframe = pd.DataFrame({'pet_id':test_data.index, 'breed_category':breeds, 'pet_category':pets})\n",
    "        submission_dataframe = submission_dataframe.set_index('pet_id', drop=True)\n",
    "        submission_dataframe.to_csv(\"submission\"+str(n)+\".csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8938147066631271,\n",
       " 0.8829307140960977,\n",
       " 0.8999203610299974,\n",
       " 0.8853198831961774]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n"
     ]
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_submission(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_data[features+['breed_category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[features+['breed_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(\"submission10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pet_id</th>\n",
       "      <th>breed_category</th>\n",
       "      <th>pet_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANSL_75005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANSL_76663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANSL_58259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANSL_67171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANSL_72871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pet_id  breed_category  pet_category\n",
       "0  ANSL_75005             1.0             2\n",
       "1  ANSL_76663             0.0             1\n",
       "2  ANSL_58259             0.0             2\n",
       "3  ANSL_67171             0.0             2\n",
       "4  ANSL_72871             0.0             2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['prod']=train_data.pet_category*train_data.breed_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_date</th>\n",
       "      <th>listing_date</th>\n",
       "      <th>condition</th>\n",
       "      <th>color_type</th>\n",
       "      <th>length(m)</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>breed_category</th>\n",
       "      <th>pet_category</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_year</th>\n",
       "      <th>issue_month</th>\n",
       "      <th>issue_day</th>\n",
       "      <th>listing_year</th>\n",
       "      <th>listing_month</th>\n",
       "      <th>listing_day</th>\n",
       "      <th>total_days</th>\n",
       "      <th>length(cm)</th>\n",
       "      <th>rec_area</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANSL_69903</th>\n",
       "      <td>2016-07-10</td>\n",
       "      <td>2016-09-21 16:25:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Brown Tabby</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.78</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>80.0</td>\n",
       "      <td>622.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSL_66892</th>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>2018-12-27 17:47:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>White</td>\n",
       "      <td>0.72</td>\n",
       "      <td>14.19</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1862</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1021.68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSL_69750</th>\n",
       "      <td>2014-09-28</td>\n",
       "      <td>2016-10-19 08:24:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40.90</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>752</td>\n",
       "      <td>15.0</td>\n",
       "      <td>613.50</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSL_71623</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2019-01-25 18:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>White</td>\n",
       "      <td>0.62</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>755</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1104.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSL_57969</th>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>2017-11-19 09:38:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.06</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>52</td>\n",
       "      <td>50.0</td>\n",
       "      <td>553.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           issue_date        listing_date  condition   color_type  length(m)  \\\n",
       "pet_id                                                                         \n",
       "ANSL_69903 2016-07-10 2016-09-21 16:25:00        2.0  Brown Tabby       0.80   \n",
       "ANSL_66892 2013-11-21 2018-12-27 17:47:00        1.0        White       0.72   \n",
       "ANSL_69750 2014-09-28 2016-10-19 08:24:00        1.0        Brown       0.15   \n",
       "ANSL_71623 2016-12-31 2019-01-25 18:30:00        1.0        White       0.62   \n",
       "ANSL_57969 2017-09-28 2017-11-19 09:38:00        2.0        Black       0.50   \n",
       "\n",
       "            height(cm)  X1  X2  breed_category  pet_category  ...  issue_year  \\\n",
       "pet_id                                                        ...               \n",
       "ANSL_69903        7.78  13   9             0.0             1  ...        2016   \n",
       "ANSL_66892       14.19  13   9             0.0             2  ...        2013   \n",
       "ANSL_69750       40.90  15   4             2.0             4  ...        2014   \n",
       "ANSL_71623       17.82   0   1             0.0             2  ...        2016   \n",
       "ANSL_57969       11.06  18   4             0.0             1  ...        2017   \n",
       "\n",
       "            issue_month  issue_day  listing_year  listing_month  listing_day  \\\n",
       "pet_id                                                                         \n",
       "ANSL_69903            7         10          2016              9           21   \n",
       "ANSL_66892           11         21          2018             12           27   \n",
       "ANSL_69750            9         28          2016             10           19   \n",
       "ANSL_71623           12         31          2019              1           25   \n",
       "ANSL_57969            9         28          2017             11           19   \n",
       "\n",
       "            total_days  length(cm)  rec_area  prod  \n",
       "pet_id                                              \n",
       "ANSL_69903          73        80.0    622.40   0.0  \n",
       "ANSL_66892        1862        72.0   1021.68   0.0  \n",
       "ANSL_69750         752        15.0    613.50   8.0  \n",
       "ANSL_71623         755        62.0   1104.84   0.0  \n",
       "ANSL_57969          52        50.0    553.00   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict pet1\n",
    "# predict breed1 \n",
    "# calculate pet1*breed1\n",
    "#use pet1*breed1 and breed1 to predict pet2\n",
    "#use pet2*breed1 to predict breed2\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet1 = GradientBoostingClassifier(random_state=13)\n",
    "breed1 = GradientBoostingClassifier(random_state=13)\n",
    "prod = GradientBoostingClassifier(random_state=13)\n",
    "pet2 = GradientBoostingClassifier(random_state=13)\n",
    "breed2 = GradientBoostingClassifier(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features = ['condition', 'length(cm)', 'height(cm)','rec_area', 'X1', 'X2', 'color_type_encoded',\n",
    "            'issue_year', 'issue_month', 'issue_day', 'listing_year', 'listing_month', 'listing_day', 'total_days']\n",
    "y_pet = train_data['pet_category'].values\n",
    "y_breed = train_data['breed_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p1_train, X_p1_valid, y_p1_train, y_p1_valid = train_test_split(train_data[features].values, \n",
    "                                                                              y_pet, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "    \n",
    "pet1.fit(X_p1_train, y_p1_train)\n",
    "scores.append(pet1.score(X_p1_valid, y_p1_valid))\n",
    "#pet1.fit(np.array(train_data[features]), y_pet)\n",
    "\n",
    "X_b1_train, X_b1_valid, y_b1_train, y_b1_valid = train_test_split(train_data[features].values, \n",
    "                                                                              y_breed, test_size=0.20)\n",
    "\n",
    "breed1.fit(X_b1_train, y_b1_train)\n",
    "scores.append(breed1.score(X_b1_valid, y_b1_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prod = train_data['prod'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prod_train, X_prod_valid, y_prod_train, y_prod_valid = train_test_split(train_data[features].values,\n",
    "                                                                         y_prod, test_size=0.2)\n",
    "prod.fit(X_prod_train, y_prod_train)\n",
    "scores.append(prod.score(X_prod_valid, y_prod_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8823997876294133, 0.8733740376957791, 0.8378019644279268]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
