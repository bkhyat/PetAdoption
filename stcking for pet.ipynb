{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "#Reading Train and Test Data\n",
    "train_data = pd.read_csv('Dataset/train.csv', index_col='pet_id')\n",
    "test_data = pd.read_csv('Dataset/test.csv', index_col='pet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Label Encoding The Color_type Column\n",
    "train_data['color_type_encoded'] = encoder.fit_transform(train_data.color_type)\n",
    "test_data['color_type_encoded'] = encoder.transform(test_data.color_type)\n",
    "\n",
    "#Filling in the NAN values for Condition Column with random array with same distribution\n",
    "train_condition=np.random.choice(np.arange(0, 3), p=[6281/17357,6819/17357,4257/17357], size=1477)\n",
    "test_condition = np.random.choice(np.arange(0,3), p=[2685/7453,2928/7453,1840/7453], size=619)\n",
    "\n",
    "train_data['condition_filled'] = 0\n",
    "test_data['condition_filled'] = 0\n",
    "\n",
    "train_data.loc[train_data.condition.isnull(), 'condition_filled'] = 1\n",
    "test_data.loc[test_data.condition.isnull(), 'condition_filled'] = 1\n",
    "\n",
    "#Adding new column indicating whether the value in Condition Column is filled \n",
    "train_data.loc[train_data.condition.isnull(), 'condition'] = -99\n",
    "test_data.loc[test_data.condition.isnull(), 'condition'] = -99\n",
    "\n",
    "#Converting Dates column to Pandas DateTime type\n",
    "train_data['issue_date'] = pd.to_datetime(train_data.issue_date)\n",
    "train_data['listing_date'] = pd.to_datetime(train_data.listing_date)\n",
    "                                            \n",
    "test_data['issue_date'] = pd.to_datetime(test_data.issue_date)\n",
    "test_data['listing_date'] = pd.to_datetime(test_data.listing_date)\n",
    "\n",
    "#Adding three new columns for day, month, year for each date columns\n",
    "train_data['issue_year'] = train_data.issue_date.dt.year\n",
    "train_data['issue_month'] = train_data.issue_date.dt.month\n",
    "train_data['issue_day'] = train_data.issue_date.dt.day\n",
    "\n",
    "train_data['listing_year'] = train_data.listing_date.dt.year\n",
    "train_data['listing_month'] = train_data.listing_date.dt.month\n",
    "train_data['listing_day'] = train_data.listing_date.dt.day\n",
    "\n",
    "test_data['issue_year'] = test_data.issue_date.dt.year\n",
    "test_data['issue_month'] = test_data.issue_date.dt.month\n",
    "test_data['issue_day'] = test_data.issue_date.dt.day\n",
    "\n",
    "test_data['listing_year'] = test_data.listing_date.dt.year\n",
    "test_data['listing_month'] = test_data.listing_date.dt.month\n",
    "test_data['listing_day'] = test_data.listing_date.dt.day\n",
    "\n",
    "#Adding a new column for Difference in Issue and Listing Dates\n",
    "train_data['total_days'] = np.array(train_data.listing_date-train_data.issue_date).astype('timedelta64[D]').astype('int64')\n",
    "test_data['total_days'] = np.array(test_data.listing_date-test_data.issue_date).astype('timedelta64[D]').astype('int64')\n",
    "\n",
    "#Adding length(cm) column, converting the values in length(m) from meter to centimeters\n",
    "train_data['length(cm)'] = train_data['length(m)']*100\n",
    "test_data['length(cm)'] = test_data['length(m)']*100\n",
    "\n",
    "#Adding a new column for representing the rectangular area for the given length and height\n",
    "train_data['rec_area'] = train_data['length(cm)'] * train_data['height(cm)']\n",
    "test_data['rec_area'] = test_data['length(cm)'] * test_data['height(cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['condition', 'length(cm)', 'height(cm)','rec_area', 'X1', 'X2', 'color_type_encoded',\n",
    "           'issue_year', 'issue_month', 'issue_day', 'listing_year', 'listing_month', 'listing_day', 'total_days']\n",
    "X = train_data[features].values\n",
    "y_pet = train_data['pet_category'].values\n",
    "y_breed = train_data['breed_category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(np.round(X.shape[0]*0.8+1))]\n",
    "X_valid = X[int(np.round(X.shape[0]*0.8+1)):]\n",
    "\n",
    "y_pet_train = y_pet[:int(np.round(y_pet.shape[0]*0.8+1))]\n",
    "y_pet_valid = y_pet[int(np.round(y_pet.shape[0]*0.8+1)):]\n",
    "\n",
    "y_breed_train = y_breed[:int(np.round(y_breed.shape[0]*0.8+1))]\n",
    "y_breed_valid = y_breed[int(np.round(y_breed.shape[0]*0.8+1)):]\n",
    "\n",
    "assert ((X_train.shape[0]+X_valid.shape[0])==X.shape[0])&\\\n",
    "((y_pet_train.shape[0]+y_pet_valid.shape[0])==y_pet.shape[0])&\\\n",
    "((y_breed_train.shape[0]+y_breed_valid.shape[0])==y_breed.shape[0]),\\\n",
    "\"Error in train validation split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, \\\n",
    "GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
    "\n",
    "pet_bagg = BaggingClassifier(random_state=13)\n",
    "pet_extra = ExtraTreesClassifier(random_state=13)\n",
    "pet_gbr = GradientBoostingClassifier(random_state=13)\n",
    "pet_rfr = RandomForestClassifier(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('bagg', pet_bagg),\n",
    "    ('extra', pet_extra),\n",
    "    ('gbr', pet_gbr),\n",
    "    ('pet', pet_rfr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thepyguy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8993627190653213"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_stack = StackingClassifier(estimators=estimators,\n",
    "                           n_jobs=4,\n",
    "                           verbose=1)\n",
    "breed_stack.fit(X_train, y_pet_train).score(X_valid, y_pet_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004248539564524"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_bagg = BaggingClassifier(random_state=13)\n",
    "breed_extra = ExtraTreesClassifier(random_state=13)\n",
    "breed_gbr = GradientBoostingClassifier(random_state=13)\n",
    "breed_rfr = RandomForestClassifier(random_state=13)\n",
    "\n",
    "estimators = [\n",
    "    ('bagg', breed_bagg),\n",
    "    ('extra', breed_extra),\n",
    "    ('gbr', breed_gbr),\n",
    "    ('pet', breed_rfr)\n",
    "]\n",
    "\n",
    "breed_tack = StackingClassifier(estimators=estimators,\n",
    "                           n_jobs=4,\n",
    "                           verbose=1)\n",
    "breed_stack.fit(X_train, y_breed_train).score(X_valid, y_breed_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_ada = AdaBoostClassifier(base_estimator=breed_stack,\n",
    "                            random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817578332448221"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_ada.fit(X_train, y_breed_train).score(X_valid, y_breed_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=13, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_bagg.fit(X_train, y_pet_train)\n",
    "pet_extra.fit(X_train, y_pet_train)\n",
    "pet_gbr.fit(X_train, y_pet_train)\n",
    "pet_rfr.fit(X_train, y_pet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
